from CompNeuroPy import opt_neuron, Experiment, current_stim
from CompNeuroPy.neuron_models import _fit_Bogacz as neuron_model
import numpy as np
from ANNarchy import dt, raster_plot
import csv
import sys


def read_data_Bogacz2016():
    nr_data_points = 32
    i_first_data_line = 3
    inj_cur_row = 0
    proto_rate_row_list = list(range(8, 26))
    arky_rate_row_list = list(range(26, 44))
    inj_current_pA = np.nan * np.ones(nr_data_points)
    proto_rate_arr = np.nan * np.ones((nr_data_points, len(proto_rate_row_list)))
    arky_rate_arr = np.nan * np.ones((nr_data_points, len(arky_rate_row_list)))

    with open("experimental_data/Bogacz_etal_2016_S1data.csv", newline="") as csvfile:
        reader = csv.reader(csvfile, delimiter=",")
        for line in reader:
            ### skip initial comment rows
            i_line = int(reader.line_num)
            if i_line < i_first_data_line:
                continue
            ### injected current
            inj_current_pA[i_line - i_first_data_line] = float(
                line[inj_cur_row].replace(",", ".")
            )
            ### proto rates
            for proto_rate_row_idx, proto_rate_row in enumerate(proto_rate_row_list):
                if len(line[proto_rate_row]) > 0:
                    proto_rate_arr[
                        i_line - i_first_data_line, proto_rate_row_idx
                    ] = float(line[proto_rate_row])
            ### arky rates
            for arky_rate_row_idx, arky_rate_row in enumerate(arky_rate_row_list):
                if len(line[arky_rate_row]) > 0:
                    arky_rate_arr[
                        i_line - i_first_data_line, arky_rate_row_idx
                    ] = float(line[arky_rate_row])
    csvfile.close()

    proto_rate_arr = np.mean(proto_rate_arr, axis=1)
    arky_rate_arr = np.mean(arky_rate_arr, axis=1)

    return {
        "inj_current_pA": inj_current_pA,
        "proto_rate_arr": proto_rate_arr,
        "arky_rate_arr": arky_rate_arr,
    }


class my_exp(Experiment):
    """
    parent class Experiment provides the variables:
        self.mon = self.cnp.Monitors() --> a CompNeuroPy Monitors object to do recordings
        self.data = {}                 --> a dictionary with any optional data
    and the functions:
        self.reset()   --> resets the model and monitors
        self.results() --> returns a results object (with recordings and optional data from self.data)
    """

    def run(self, population_name):
        """
        the function which defines the experiment

        here recordings have to be defined and simulations have to be run

        to use the experiment for the opt_neuron class, the arguments have to be:
            self - the experiment object
            population_name - the name of the population which contains a single neuron. this will be automatically provided by opt_neuron
        """

        ### run simulation/recordings
        exp_data = read_data_Bogacz2016()
        rate_arr_target_mask = np.logical_not(
            np.isnan(exp_data[f"{which_neuron}_rate_arr"])
        )
        inj_current_pA_arr = exp_data["inj_current_pA"][rate_arr_target_mask]
        t_init = 500
        t_sim = 1000
        self.mon.start()
        for inj_current_pA in inj_current_pA_arr:
            current_stim(population_name, t=t_init + t_sim, a=inj_current_pA)
            self.reset()
        ### SIMULATION END

        ### store additional data
        self.data["population_name"] = population_name
        self.data["time_step"] = dt()
        self.data["t_init"] = t_init
        self.data["t_sim"] = t_sim

        ### return results
        return self.results()


def get_loss(results_ist, results_soll, return_ist=False):
    """
    results_soll: any
        contains the target data
        provided during initialization of opt_neuron
    results_ist: object
        the results object generated by the experiment
    """

    ### get the recordings and other important things from the results_ist (results generated during the optimization using the defrined experiment from above)
    rec_ist = results_ist.recordings
    rec_times_ist = results_ist.recording_times
    pop_ist = results_ist.data["population_name"]
    t_init = results_ist.data["t_init"]

    ### get the important data for calculating the loss from the results_soll (target data directly provided to opt_neuron)
    rate_arr_target = results_soll[f"{which_neuron}_rate_arr"]
    rate_arr_target_mask = np.logical_not(np.isnan(rate_arr_target))
    rate_arr_target = rate_arr_target[rate_arr_target_mask]

    ### get the important data for calculating the loss from the recordings
    rate_arr_ist = np.ones(len(rate_arr_target)) * np.nan
    t_init = 500
    for chunk in range(len(rec_ist)):
        spike_dict = rec_ist[chunk][f"{pop_ist};spike"]
        t, _ = raster_plot(spike_dict)
        start_time, end_time = rec_times_ist.time_lims(chunk=chunk)
        ### only count spikes after t_init
        nbr_spikes = np.sum(t > (start_time + t_init))
        duration = end_time - (start_time + t_init)
        rate_arr_ist[chunk] = nbr_spikes / (duration / 1000)

    ### calculate the loss
    rmse = np.sqrt(np.mean((rate_arr_target - rate_arr_ist) ** 2))

    ### return the loss
    if return_ist:
        return {"ist": rate_arr_ist, "target": rate_arr_target}
    else:
        return rmse


if __name__ == "__main__":

    ### which variables should be optimized and between which bounds (min and max values)
    variation = 0.5
    variables_bounds = {
        "a": [0.0054 * (1 - variation), 0.0054 * (1 + variation)],
        "b": [0.34 * (1 - variation), 0.34 * (1 - variation) * (1 + variation)],
        "c": [-71 - 10, -71 + 10],
        "d": [9.81 * (1 - variation), 9.81 * (1 + variation)],
        "n0": [113 * (1 - variation), 113 * (1 + variation)],
        "n1": [4.47 * (1 - variation), 4.47 * (1 + variation)],
        "n2": [0.04 * (1 - variation), 0.04 * (1 + variation)],
        "x": [1, 3],
        "tau_ampa": 1,
        "tau_gaba": 1,
        "E_ampa": 0,
        "E_gaba": 0,
        "increase_noise": 0,
        "rates_noise": 0,
    }

    which_neuron = ["proto", "arky"][int(sys.argv[1])]
    sim_id = int(sys.argv[2])

    ### run optimization
    opt = opt_neuron(
        experiment=my_exp,
        get_loss_function=get_loss,
        variables_bounds=variables_bounds,
        results_soll=read_data_Bogacz2016(),
        time_step=0.1,
        compile_folder_name=f"annarchy_opt_{which_neuron}_{sim_id}",
        neuron_model=neuron_model,
        method="hyperopt",
        record=["spike"],
    )

    ### run the optimization, define how often the experiment should be repeated
    opt.run(max_evals=30000, results_file_name=f"best_{which_neuron}_{sim_id}.npy")
