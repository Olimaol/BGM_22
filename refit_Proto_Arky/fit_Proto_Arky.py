from CompNeuroPy import opt_neuron, Experiment, current_stim
from CompNeuroPy.neuron_models import _fit_Bogacz as neuron_model
import numpy as np
from ANNarchy import dt, raster_plot
import csv
import sys


def read_data_Bogacz2016():
    nr_data_points = 32
    i_first_data_line = 3
    inj_cur_row = 0
    proto_rate_row_list = list(range(8, 26))
    arky_rate_row_list = list(range(26, 44))
    inj_current_pA = np.nan * np.ones(nr_data_points)
    proto_rate_arr = np.nan * np.ones((nr_data_points, len(proto_rate_row_list)))
    arky_rate_arr = np.nan * np.ones((nr_data_points, len(arky_rate_row_list)))

    with open("experimental_data/Bogacz_etal_2016_S1data.csv", newline="") as csvfile:
        reader = csv.reader(csvfile, delimiter=",")
        for line in reader:
            ### skip initial comment rows
            i_line = int(reader.line_num)
            if i_line < i_first_data_line:
                continue
            ### injected current
            inj_current_pA[i_line - i_first_data_line] = float(
                line[inj_cur_row].replace(",", ".")
            )
            ### proto rates
            for proto_rate_row_idx, proto_rate_row in enumerate(proto_rate_row_list):
                if len(line[proto_rate_row]) > 0:
                    proto_rate_arr[
                        i_line - i_first_data_line, proto_rate_row_idx
                    ] = float(line[proto_rate_row])
            ### arky rates
            for arky_rate_row_idx, arky_rate_row in enumerate(arky_rate_row_list):
                if len(line[arky_rate_row]) > 0:
                    arky_rate_arr[
                        i_line - i_first_data_line, arky_rate_row_idx
                    ] = float(line[arky_rate_row])
    csvfile.close()

    proto_rate_arr = np.mean(proto_rate_arr, axis=1)
    arky_rate_arr = np.mean(arky_rate_arr, axis=1)

    return {
        "inj_current_pA": inj_current_pA,
        "proto_rate_arr": proto_rate_arr,
        "arky_rate_arr": arky_rate_arr,
    }


class my_exp(Experiment):
    """
    parent class Experiment provides the variables:
        self.mon = self.cnp.Monitors() --> a CompNeuroPy Monitors object to do recordings
        self.data = {}                 --> a dictionary with any optional data
    and the functions:
        self.reset()   --> resets the model and monitors
        self.results() --> returns a results object (with recordings and optional data from self.data)
    """

    def run(self, population_name):
        """
        the function which defines the experiment

        here recordings have to be defined and simulations have to be run

        to use the experiment for the opt_neuron class, the arguments have to be:
            self - the experiment object
            population_name - the name of the population which contains a single neuron. this will be automatically provided by opt_neuron
        """

        ### run simulation/recordings
        exp_data = read_data_Bogacz2016()
        rate_arr_target_mask = np.logical_not(
            np.isnan(exp_data[f"{which_neuron}_rate_arr"])
        )
        inj_current_pA_arr = exp_data["inj_current_pA"][rate_arr_target_mask]

        ### injected current Lorenz
        if replicate_Lorenz:
            inj_current_pA_arr = inj_current_pA_arr / 1000

        t_init = 500
        t_sim = 1000
        self.mon.start()
        for inj_current_pA in inj_current_pA_arr:
            current_stim(population_name, t=t_init + t_sim, a=inj_current_pA)
            self.reset()
        ### SIMULATION END

        ### store additional data
        self.data["population_name"] = population_name
        self.data["time_step"] = dt()
        self.data["t_init"] = t_init
        self.data["t_sim"] = t_sim

        ### return results
        return self.results()


def get_loss(results_ist, results_soll, return_ist=False, which_neuron="proto"):
    """
    results_soll: any
        contains the target data
        provided during initialization of opt_neuron
    results_ist: object
        the results object generated by the experiment
    """

    ### get the recordings and other important things from the results_ist (results generated during the optimization using the defrined experiment from above)
    rec_ist = results_ist.recordings
    rec_times_ist = results_ist.recording_times
    pop_ist = results_ist.data["population_name"]
    t_init = results_ist.data["t_init"]

    ### get the important data for calculating the loss from the results_soll (target data directly provided to opt_neuron)
    rate_arr_target = results_soll[f"{which_neuron}_rate_arr"]
    rate_arr_target_mask = np.logical_not(np.isnan(rate_arr_target))
    rate_arr_target = rate_arr_target[rate_arr_target_mask]
    inj_current_pA = results_soll["inj_current_pA"][rate_arr_target_mask]

    ### get the important data for calculating the loss from the recordings
    rate_arr_ist = np.ones(len(rate_arr_target)) * np.nan
    for chunk in range(len(rec_ist)):
        spike_dict = rec_ist[chunk][f"{pop_ist};spike"]
        t, _ = raster_plot(spike_dict)
        start_time, end_time = rec_times_ist.time_lims(chunk=chunk)
        ### only count spikes after t_init
        nbr_spikes = np.sum(t > (start_time + t_init))
        duration = end_time - (start_time + t_init)
        rate_arr_ist[chunk] = nbr_spikes / (duration / 1000)

    ### calculate the loss
    rmse = np.sqrt(np.mean((rate_arr_target - rate_arr_ist) ** 2))

    ### return the loss
    if return_ist:
        return {
            "ist": rate_arr_ist,
            "target": rate_arr_target,
            "inj_current_pA": inj_current_pA,
        }
    else:
        return rmse


if __name__ == "__main__":

    ### to replicate lorenz fits:
    replicate_Lorenz = False
    ### to use already fitted values
    use_fitted_params = True
    fitted_params_proto = {
        "a": 0.039191890241715294,
        "b": 0.000548238111291427,
        "c": -49.88014418530518,
        "d": 108.0208225074675,
        "n0": 24.2219699019072,
        "n1": 1.1929776239208976,
        "n2": 0.08899515481507077,
    }
    fitted_params_arky = {
        "a": 0.02838072375428212,
        "b": 0.19512028115003693,
        "c": -42.5741678730728,
        "d": 145.05548508832746,
        "n0": 0.13769286237123363,
        "n1": 0.00485927350881888,
        "n2": 0.04806752535231682,
    }
    fitted_params = [fitted_params_proto, fitted_params_arky][int(sys.argv[1])]

    ### 1. use old paramters
    ### 2. also use parameter "R_input_megOhm"
    ### 3. divide input current by 1000
    ### 4. set refractory to 5
    ### this is not how the neuron models are used in the BG model!!!
    lorenz_params_proto = {
        "a": 0.0058,
        "b": 0.56,
        "c": -65,
        "d": 3.8,
        "n0": 117,
        "n1": 4.86,
        "n2": 0.043,
        "x": 1,
        "R_input_megOhm": 450,
    }
    lorenz_params_arky = {
        "a": 0.0054,
        "b": 0.34,
        "c": -71,
        "d": 9.81,
        "n0": 113,
        "n1": 4.47,
        "n2": 0.04,
        "x": 1,
        "R_input_megOhm": 560,
    }
    lorenz_params = [lorenz_params_proto, lorenz_params_arky][int(sys.argv[1])]

    ### which variables should be optimized and between which bounds (min and max values)
    variables_bounds = {
        "a": [0.01, 0.1],
        "b": [0, 1],
        "c": [-80, -40],
        "d": [100, 300],
        "n0": [0, 200],
        "n1": [0, 10],
        "n2": [0, 0.1],
        "R_input_megOhm": 1,
        "x": 1,
        "tau_ampa": 1,
        "tau_gaba": 1,
        "E_ampa": 0,
        "E_gaba": 0,
        "increase_noise": 0,
        "rates_noise": 0,
        "r": 0,
    }

    if replicate_Lorenz:
        for key, val in lorenz_params.items():
            variables_bounds[key] = val
        variables_bounds["r"] = [0, 1]
        neuron_model.refractory = 5

    if use_fitted_params:
        for key, val in fitted_params.items():
            variables_bounds[key] = val
        variables_bounds["r"] = [0, 1]

    which_neuron = ["proto", "arky"][int(sys.argv[1])]
    sim_id = int(sys.argv[2])

    ### run optimization
    opt = opt_neuron(
        experiment=my_exp,
        get_loss_function=lambda a, b: get_loss(a, b, False, which_neuron),
        variables_bounds=variables_bounds,
        results_soll=read_data_Bogacz2016(),
        time_step=0.1,
        compile_folder_name=f"annarchy_opt_{which_neuron}_{sim_id}",
        neuron_model=neuron_model,
        method="hyperopt",
        record=["spike"],
    )

    ### run the optimization, define how often the experiment should be repeated
    opt.run(max_evals=1, results_file_name=f"best_{which_neuron}_{sim_id}.npy")

    ### f-I curve losses of Lorenz fits: proto=1.4, arky=0.9

    ### our fit with nonlin:
    # proto: 0.5176893289799147
    # params = {
    #     "a": 0.004894445882993041,
    #     "b": 0.23006342384188397,
    #     "c": -67.23776038895387,
    #     "d": 4.9173032745663745,
    #     "n0": 63.59418875142282,
    #     "n1": 3.3423140577041557,
    #     "n2": 0.05050316999730628,
    #     "x": 1.2421189138561222,
    # }
    # arky=0.5460968621452967
    # params = {
    #     "a": 0.007839724855153347,
    #     "b": 0.24405376283085636,
    #     "c": -63.44134773165609,
    #     "d": 11.531786006917402,
    #     "n0": 56.643875300238896,
    #     "n1": 3.4175566589342337,
    #     "n2": 0.045725149196710974,
    #     "x": 1.2537563498780842,
    # }

    ### our fit without nonlin:
    # proto: 1.262563836453022
    # params = {
    #     "a": 0.039191890241715294,
    #     "b": 0.000548238111291427,
    #     "c": -49.88014418530518,
    #     "d": 108.0208225074675,
    #     "n0": 24.2219699019072,
    #     "n1": 1.1929776239208976,
    #     "n2": 0.08899515481507077,
    # }
    # arky=0.7259982322564168
    # params = {
    #     "a": 0.02838072375428212,
    #     "b": 0.19512028115003693,
    #     "c": -42.5741678730728,
    #     "d": 145.05548508832746,
    #     "n0": 0.13769286237123363,
    #     "n1": 0.00485927350881888,
    #     "n2": 0.04806752535231682,
    # }
